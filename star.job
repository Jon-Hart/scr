# bwa alignment to reference genome
#PBS -l walltime=8:00:00
#PBS -l cput=64:00:00
#PBS -l nodes=1:ppn=8
#PBS -l mem=30gb
#PBS -j oe

# Adjust the cput as appropriate.  The main part of this job is the bwa
# alignment.  In my experience it takes about 75,000s per 17 million reads a
# bit over 1 hour per million.  You can get the job to schedule faster by
# setting this to a smaller value.  walltime should be set to cput/6 or so to
# be on the safe side.

# requires 4gb of ram for the reference plus 500mb of ram for each additional
# thread 8gb total but in my experience this is incorrect.  For 20million 100bp
# reads on 8 cores I had a peak usage of 19gb latest version now wants 3.2gb
# per thread so 19gb might need to go up to 26gb need to have $INPUT_FILE for
# the input fastq and $PREFIX_FILE for the output files defined

#use the local scratch drive
cd $PBSTMPDIR
rm -r *

#clean up variables
if ( $INPUT_FILE =~ "" ) then
	unsetenv INPUT_FILE
endif
if ( $PREFIX_FILE =~ "" ) then
	unsetenv PREFIX_FILE
endif
if ( $OUTPUT_DIR =~ "" ) then
	unsetenv OUTPUT_DIR
endif
if ( $GENOME_FILE =~ "" ) then
	unsetenv GENOME_FILE
endif

#sanity check
if (! $?INPUT_FILE) then
	echo "Input file must be defined"
	exit
endif

# copy and extract the input file if needed
/usr/bin/time -v cp $INPUT_FILE .
set filename=`basename "$INPUT_FILE"`
if ($filename:e == "gz") then
	/usr/bin/time -v unpigz $filename
	set filename=$filename:r
endif

if (! $?PREFIX_FILE) then
	echo "Output prefix not defined.  Defaulting to input file for prefix."
	set PREFIX_FILE=$filename
endif

# setup the following steps
mv $filename $PREFIX_FILE.fq

# trimming
# usage: fastq_quality_trimmer [-h] [-v] [-t N] [-l N] [-z] [-i INFILE] [-o OUTFILE]
# Part of FASTX Toolkit 0.0.13 by A. Gordon (gordon@cshl.edu)
# 
#    [-h]         = This helpful help screen.
#    [-t N]       = Quality threshold - nucleotides with lower 
#                   quality will be trimmed (from the end of the sequence).
#    [-l N]       = Minimum length - sequences shorter than this (after trimming)
#                   will be discarded. Default = 0 = no minimum length. 
#    [-z]         = Compress output with GZIP.
#    [-i INFILE]  = FASTQ input file. default is STDIN.
#    [-o OUTFILE] = FASTQ output file. default is STDOUT.
#    [-v]         = Verbose - report number of sequences.
#                   If [-o] is specified,  report will be printed to STDOUT.
#                   If [-o] is not specified (and output goes to STDOUT),
#                   report will be printed to STDERR.
# -Q33 sets Illumina 1.8 style quality values

module load fastx
/usr/bin/time -v fastq_quality_trimmer -Q33 -t 18 -l 20  -i $PREFIX_FILE.fq -o $PREFIX_FILE.fil.fq
rm $PREFIX_FILE.fq
mv $PREFIX_FILE.fil.fq $PREFIX_FILE.fq
module unload fastx

# fastqc
#             FastQC - A high throughput sequence QC analysis tool
# 
# SYNOPSIS
# 
# 	fastqc seqfile1 seqfile2 .. seqfileN
# 
#     fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] 
#            [-c contaminant file] seqfile1 .. seqfileN
# 
# DESCRIPTION
# 
#     FastQC reads a set of sequence files and produces from each one a quality
#     control report consisting of a number of different modules, each one of 
#     which will help to identify a different potential type of problem in your
#     data.
#     
#     If no files to process are specified on the command line then the program
#     will start as an interactive graphical application.  If files are provided
#     on the command line then the program will run with no user interaction
#     required.  In this mode it is suitable for inclusion into a standardised
#     analysis pipeline.
#     
#     The options for the program as as follows:
#     
#     -h --help       Print this help file and exit
#     
#     -v --version    Print the version of the program and exit
#     
#     -o --outdir     Create all output files in the specified output directory.
#                     Please note that this directory must exist as the program
#                     will not create it.  If this option is not set then the 
#                     output file for each sequence file is created in the same
#                     directory as the sequence file which was processed.
#                     
#     --casava        Files come from raw casava output. Files in the same sample
#                     group (differing only by the group number) will be analysed
#                     as a set rather than individually. Sequences with the filter
#                     flag set in the header will be excluded from the analysis.
#                     Files must have the same names given to them by casava
#                     (including being gzipped and ending with .gz) otherwise they
#                     won't be grouped together correctly.
#                    
#     --extract       If set then the zipped output file will be uncompressed in
#                     the same directory after it has been created.  By default
#                     this option will be set if fastqc is run in non-interactive
#                     mode.
#                     
#     -j --java       Provides the full path to the java binary you want to use to
#                     launch fastqc. If not supplied then java is assumed to be in
#                     your path.
#                    
#     --noextract     Do not uncompress the output file after creating it.  You
#                     should set this option if you do not wish to uncompress
#                     the output when running in non-interactive mode.
#                     
#     --nogroup       Disable grouping of bases for reads >50bp. All reports will
#                     show data for every base in the read.  WARNING: Using this
#                     option will cause fastqc to crash and burn if you use it on
#                     really long reads, and your plots may end up a ridiculous size.
#                     You have been warned!
#                     
#     -f --format     Bypasses the normal sequence file format detection and
#                     forces the program to use the specified format.  Valid
#                     formats are bam,sam,bam_mapped,sam_mapped and fastq
#                     
#     -t --threads    Specifies the number of files which can be processed
#                     simultaneously.  Each thread will be allocated 250MB of
#                     memory so you shouldn't run more threads than your
#                     available memory will cope with, and not more than
#                     6 threads on a 32 bit machine
#                   
#     -c              Specifies a non-default file which contains the list of
#     --contaminants  contaminants to screen overrepresented sequences against.
#                     The file must contain sets of named contaminants in the
#                     form name[tab]sequence.  Lines prefixed with a hash will
#                     be ignored.
#                     
#    -k --kmers       Specifies the length of Kmer to look for in the Kmer content
#                     module. Specified Kmer length must be between 2 and 10. Default
#                     length is 5 if not specified.
#                     
#    -q --quiet       Supress all progress messages on stdout and only report errors.
#                     
# BUGS
# 
#     Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk
#     or in www.bioinformatics.babraham.ac.uk/bugzilla/
# 
# 
module load fastqc
/usr/bin/time -v fastqc -t 8 $PREFIX_FILE.fq
module unload fastqc

# copy your genome file
#cp -r /gpfs/group/databases/Homo_sapiens/star.genome .
# load bwa and samtools
module load star
module load samtools

# first pass this takes about about 40M reads per hour on 8 cores, so adjust the timing as needed
/usr/bin/time -v STAR --genomeDir /gpfs/group/databases/Homo_sapiens/star.genome --readFilesIn $PREFIX_FILE.fq --runThreadN 8 --genomeLoad LoadAndRemove --outStd SAM --outSAMmode Full > /dev/null

# use the detected junctions to generate a new genome. This is slow at about 2 hours to regenerate the indexes.  
rm -r star.genome
mv SJ.out.tab SJ.out.pass1.tab
rm Aligned.out.sam
mkdir /gpfs/group/vogt/shared/star.genome.$PREFIX_FILE
/usr/bin/time -v STAR --runMode genomeGenerate --genomeDir /gpfs/group/vogt/shared/star.genome.$PREFIX_FILE --genomeFastaFiles /gpfs/group/vogt/shared/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/*.fa \
  --sjdbFileChrStartEnd SJ.out.pass1.tab --sjdbOverhang 75 --runThreadN 8 --genomeLoad LoadAndKeep

# use the new genome to make a second pass  Again about 40m per hour.
/usr/bin/time -v STAR --genomeDir /gpfs/group/vogt/shared/star.genome.$PREFIX_FILE --readFilesIn $PREFIX_FILE.fq --runThreadN 8 --genomeLoad LoadAndRemove \
   --outStd SAM --outSAMmode Full |  samtools view -bS - > star.$PREFIX_FILE.bam

# sort
samtools sort star.$PREFIX_FILE.bam star.$PREFIX_FILE.sorted.bam
rm star.$PREFIX_FILE.bam

# index
samtools index star.$PREFIX_FILE.sorted.bam


# unload the modules
module unload samtools
module unload star

# remove the genome files and input fastq and intermediate sai file
rm -r /gpfs/group/vogt/shared/star.genome.$PREFIX_FILE
rm $PREFIX_FILE.fq

# tar cfvz bwa.$PREFIX_FILE.tgz *
tar cv * | pigz -9 -p 8 > $OUTPUT_DIR/star.$PREFIX_FILE.tgz
exit
